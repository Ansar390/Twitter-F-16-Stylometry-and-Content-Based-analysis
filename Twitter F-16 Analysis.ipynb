{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxlzLZvBRoXP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import scipy\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression as Log_Reg\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GRAD_BOOST\n",
        "from sklearn.ensemble import RandomForestClassifier as RFCL\n",
        "#pip install scikit-learn-extra\n",
        "#from sklearn_extra.cluster import KMedoids\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8E3E-6PRoXW"
      },
      "source": [
        "## Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQEogO8URoXc",
        "outputId": "8ae8fe6a-2612-4c55-905a-a249e2a66909"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'Frances Grau (11.09.2013) on mass media, soc...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'#Jotakeirabaziarte @minte1974\\r\\nZorionak! @...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'Editing Dairy Goat Journal. Finally, somethi...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'Have you used a Venn Diagram to differentiat...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'Have some fun &amp;amp; help save the Earth! Yik...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>b'Mejora tu marketing web online monitorizando...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>b'Dear friend,\\nLike my Facebook Page\\nhttp://...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>b'#PAC-12 has strong presence on preseason col...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>b'Listening to @clsaarinen&amp;#39;s wonderful pre...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>b'Viewing my find on #NearMap http://bit.ly/qj...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>425 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweet   label\n",
              "0    b'Frances Grau (11.09.2013) on mass media, soc...    male\n",
              "1    b'#Jotakeirabaziarte @minte1974\\r\\nZorionak! @...    male\n",
              "2    b'Editing Dairy Goat Journal. Finally, somethi...    male\n",
              "3    b'Have you used a Venn Diagram to differentiat...  female\n",
              "4    b'Have some fun &amp; help save the Earth! Yik...    male\n",
              "..                                                 ...     ...\n",
              "420  b'Mejora tu marketing web online monitorizando...  female\n",
              "421  b'Dear friend,\\nLike my Facebook Page\\nhttp://...    male\n",
              "422  b'#PAC-12 has strong presence on preseason col...    male\n",
              "423  b'Listening to @clsaarinen&#39;s wonderful pre...  female\n",
              "424  b'Viewing my find on #NearMap http://bit.ly/qj...    male\n",
              "\n",
              "[425 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "female = []\n",
        "for root, dirs, files_read in os.walk(r'C:\\Users\\Ansar\\Desktop\\New folder\\corpus\\female'):\n",
        "    for file in files_read:\n",
        "        if file.endswith('.txt'):\n",
        "            with open(os.path.join(root, file), 'rb') as f:\n",
        "                data = f.read()\n",
        "                female.append(data)\n",
        "df_female= pd.DataFrame(female)\n",
        "df_female=df_female.rename(columns={0: 'tweet'})\n",
        "df_female['label']='female'\n",
        "\n",
        "\n",
        "male = []\n",
        "for root, dirs, files_read in os.walk(r'C:\\Users\\Ansar\\Desktop\\New folder\\corpus\\male'):\n",
        "    for file in files_read:\n",
        "        if file.endswith('.txt'):\n",
        "            with open(os.path.join(root, file), 'rb') as f:\n",
        "                data = f.read()\n",
        "                male.append(data)\n",
        "df_male= pd.DataFrame(male)\n",
        "df_male=df_male.rename(columns={0: 'tweet'})\n",
        "\n",
        "df_male['label']='male'\n",
        "df = pd.concat([df_male, df_female], axis=0,ignore_index=True)\n",
        "df = df.sample(frac = 1)\n",
        "df=df.reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xar2XRyjRoXe"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFHFtfyZRoXf",
        "outputId": "1f8a13ba-8a2b-4d5a-b91a-6b37bda0aacd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Ansar\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words=set(stopwords.words('english'))\n",
        "data = [] \n",
        "for lp in range(0, 425):\n",
        "    clean_data = re.sub('[^a-zA-Z]', ' ', str((df['tweet'][lp])))\n",
        "    clean_data.lower()\n",
        "    clean_data = clean_data.split()\n",
        "\n",
        "    clean_data=[word for word in clean_data if not word in stop_words]\n",
        "    clean_data = ' '.join(clean_data)\n",
        "    data.append(clean_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ManRtpiRoXg"
      },
      "source": [
        "## Stylometry Based Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYSmdVPCRoXh",
        "outputId": "e3c6bd7f-4ad6-4588-d63c-8bba1def1888"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Colon</th>\n",
              "      <th>Sharp</th>\n",
              "      <th>Digits</th>\n",
              "      <th>Opening_bracket</th>\n",
              "      <th>Closing_bracket</th>\n",
              "      <th>Equal</th>\n",
              "      <th>Dash</th>\n",
              "      <th>Question_mark</th>\n",
              "      <th>Percentage</th>\n",
              "      <th>Ampersand</th>\n",
              "      <th>Full_stop</th>\n",
              "      <th>Underscore</th>\n",
              "      <th>Exclamation_mark</th>\n",
              "      <th>Capital_letter</th>\n",
              "      <th>Semi_colon</th>\n",
              "      <th>Comma</th>\n",
              "      <th>Space</th>\n",
              "      <th>Small_letters</th>\n",
              "      <th>Slash</th>\n",
              "      <th>At_sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>630</td>\n",
              "      <td>534</td>\n",
              "      <td>3598</td>\n",
              "      <td>52</td>\n",
              "      <td>56</td>\n",
              "      <td>48</td>\n",
              "      <td>660</td>\n",
              "      <td>118</td>\n",
              "      <td>22</td>\n",
              "      <td>902</td>\n",
              "      <td>67139</td>\n",
              "      <td>142</td>\n",
              "      <td>74</td>\n",
              "      <td>66496</td>\n",
              "      <td>910</td>\n",
              "      <td>234</td>\n",
              "      <td>5758</td>\n",
              "      <td>32364</td>\n",
              "      <td>1466</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>188</td>\n",
              "      <td>540</td>\n",
              "      <td>2754</td>\n",
              "      <td>96</td>\n",
              "      <td>98</td>\n",
              "      <td>22</td>\n",
              "      <td>274</td>\n",
              "      <td>174</td>\n",
              "      <td>28</td>\n",
              "      <td>702</td>\n",
              "      <td>83837</td>\n",
              "      <td>148</td>\n",
              "      <td>118</td>\n",
              "      <td>82806</td>\n",
              "      <td>708</td>\n",
              "      <td>348</td>\n",
              "      <td>10644</td>\n",
              "      <td>41534</td>\n",
              "      <td>428</td>\n",
              "      <td>692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1104</td>\n",
              "      <td>945</td>\n",
              "      <td>4970</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>73</td>\n",
              "      <td>1797</td>\n",
              "      <td>143</td>\n",
              "      <td>90</td>\n",
              "      <td>1081</td>\n",
              "      <td>126763</td>\n",
              "      <td>741</td>\n",
              "      <td>143</td>\n",
              "      <td>125668</td>\n",
              "      <td>1085</td>\n",
              "      <td>210</td>\n",
              "      <td>11484</td>\n",
              "      <td>62616</td>\n",
              "      <td>3218</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>690</td>\n",
              "      <td>437</td>\n",
              "      <td>1867</td>\n",
              "      <td>9</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>110</td>\n",
              "      <td>11</td>\n",
              "      <td>456</td>\n",
              "      <td>58677</td>\n",
              "      <td>64</td>\n",
              "      <td>74</td>\n",
              "      <td>57957</td>\n",
              "      <td>460</td>\n",
              "      <td>172</td>\n",
              "      <td>6626</td>\n",
              "      <td>29817</td>\n",
              "      <td>1103</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>116</td>\n",
              "      <td>174</td>\n",
              "      <td>324</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>42</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>10827</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>10660</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>860</td>\n",
              "      <td>5656</td>\n",
              "      <td>430</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>102</td>\n",
              "      <td>46</td>\n",
              "      <td>388</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>9447</td>\n",
              "      <td>28</td>\n",
              "      <td>36</td>\n",
              "      <td>9346</td>\n",
              "      <td>68</td>\n",
              "      <td>4</td>\n",
              "      <td>826</td>\n",
              "      <td>4518</td>\n",
              "      <td>194</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>1263</td>\n",
              "      <td>82</td>\n",
              "      <td>39708</td>\n",
              "      <td>40</td>\n",
              "      <td>102</td>\n",
              "      <td>18</td>\n",
              "      <td>1414</td>\n",
              "      <td>112</td>\n",
              "      <td>7</td>\n",
              "      <td>1167</td>\n",
              "      <td>236601</td>\n",
              "      <td>21</td>\n",
              "      <td>1392</td>\n",
              "      <td>235469</td>\n",
              "      <td>1168</td>\n",
              "      <td>241</td>\n",
              "      <td>9801</td>\n",
              "      <td>162798</td>\n",
              "      <td>3492</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>161</td>\n",
              "      <td>428</td>\n",
              "      <td>1451</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>44</td>\n",
              "      <td>484</td>\n",
              "      <td>194</td>\n",
              "      <td>1</td>\n",
              "      <td>479</td>\n",
              "      <td>52793</td>\n",
              "      <td>70</td>\n",
              "      <td>60</td>\n",
              "      <td>52046</td>\n",
              "      <td>483</td>\n",
              "      <td>334</td>\n",
              "      <td>6615</td>\n",
              "      <td>26325</td>\n",
              "      <td>468</td>\n",
              "      <td>394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>1268</td>\n",
              "      <td>480</td>\n",
              "      <td>4317</td>\n",
              "      <td>88</td>\n",
              "      <td>144</td>\n",
              "      <td>95</td>\n",
              "      <td>870</td>\n",
              "      <td>166</td>\n",
              "      <td>6</td>\n",
              "      <td>1430</td>\n",
              "      <td>119008</td>\n",
              "      <td>53</td>\n",
              "      <td>209</td>\n",
              "      <td>117475</td>\n",
              "      <td>1434</td>\n",
              "      <td>250</td>\n",
              "      <td>11486</td>\n",
              "      <td>58762</td>\n",
              "      <td>3103</td>\n",
              "      <td>455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>68</td>\n",
              "      <td>9</td>\n",
              "      <td>216</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>5113</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>4975</td>\n",
              "      <td>28</td>\n",
              "      <td>9</td>\n",
              "      <td>462</td>\n",
              "      <td>2590</td>\n",
              "      <td>160</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>425 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Colon  Sharp  Digits  Opening_bracket  Closing_bracket  Equal  Dash  \\\n",
              "0      630    534    3598               52               56     48   660   \n",
              "1      188    540    2754               96               98     22   274   \n",
              "2     1104    945    4970                7                7     73  1797   \n",
              "3      690    437    1867                9               42      0    54   \n",
              "4      116    174     324                0                2     16    42   \n",
              "..     ...    ...     ...              ...              ...    ...   ...   \n",
              "420    102     46     388               18               50      0    70   \n",
              "421   1263     82   39708               40              102     18  1414   \n",
              "422    161    428    1451               20               22     44   484   \n",
              "423   1268    480    4317               88              144     95   870   \n",
              "424     68      9     216                2                2      7    40   \n",
              "\n",
              "     Question_mark  Percentage  Ampersand  Full_stop  Underscore  \\\n",
              "0              118          22        902      67139         142   \n",
              "1              174          28        702      83837         148   \n",
              "2              143          90       1081     126763         741   \n",
              "3              110          11        456      58677          64   \n",
              "4               20           2        150      10827          14   \n",
              "..             ...         ...        ...        ...         ...   \n",
              "420             10           2         68       9447          28   \n",
              "421            112           7       1167     236601          21   \n",
              "422            194           1        479      52793          70   \n",
              "423            166           6       1430     119008          53   \n",
              "424              8           0         28       5113          35   \n",
              "\n",
              "     Exclamation_mark  Capital_letter  Semi_colon  Comma  Space  \\\n",
              "0                  74           66496         910    234   5758   \n",
              "1                 118           82806         708    348  10644   \n",
              "2                 143          125668        1085    210  11484   \n",
              "3                  74           57957         460    172   6626   \n",
              "4                  38           10660         150      0    860   \n",
              "..                ...             ...         ...    ...    ...   \n",
              "420                36            9346          68      4    826   \n",
              "421              1392          235469        1168    241   9801   \n",
              "422                60           52046         483    334   6615   \n",
              "423               209          117475        1434    250  11486   \n",
              "424                 4            4975          28      9    462   \n",
              "\n",
              "     Small_letters  Slash  At_sign  \n",
              "0            32364   1466      558  \n",
              "1            41534    428      692  \n",
              "2            62616   3218      227  \n",
              "3            29817   1103      229  \n",
              "4             5656    430       52  \n",
              "..             ...    ...      ...  \n",
              "420           4518    194      202  \n",
              "421         162798   3492      101  \n",
              "422          26325    468      394  \n",
              "423          58762   3103      455  \n",
              "424           2590    160       11  \n",
              "\n",
              "[425 rows x 20 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stylo_lstt=[':','#','([0-9])','\\\\(','\\\\)','=','-','\\?','%','&','.','_','!','([A-Z]*)',';',',',' ','([a-z]*)','/','@']\n",
        "\n",
        "stylo_list=[]\n",
        "for outer_loop in stylo_lstt:\n",
        "    for inner_loop in range(0,len(df)):\n",
        "            itering = re.findall(outer_loop, str(df['tweet'][inner_loop]))\n",
        "            counting= len(itering)\n",
        "            stylo_list.append(counting)\n",
        "rows = 425\n",
        "chunks = [stylo_list[itr:itr+rows] for itr in range(0, len(stylo_list), rows)]\n",
        "chunks=np.array(chunks)\n",
        "chunks=chunks.T\n",
        "df_stylo=pd.DataFrame(chunks,columns=['Colon','Sharp','Digits','Opening_bracket',\n",
        "                                 'Closing_bracket','Equal','Dash','Question_mark',\n",
        "                                 'Percentage','Ampersand','Full_stop','Underscore',\n",
        "                                 'Exclamation_mark','Capital_letter','Semi_colon',\n",
        "                                 'Comma','Space','Small_letters','Slash','At_sign'])\n",
        "df_stylo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuLDz8n3RoXi",
        "outputId": "6c0e9972-c5da-463a-ba57-043f5cd54356"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  630,   534,  3598, ..., 32364,  1466,   558],\n",
              "       [  188,   540,  2754, ..., 41534,   428,   692],\n",
              "       [ 1104,   945,  4970, ..., 62616,  3218,   227],\n",
              "       ...,\n",
              "       [  161,   428,  1451, ..., 26325,   468,   394],\n",
              "       [ 1268,   480,  4317, ..., 58762,  3103,   455],\n",
              "       [   68,     9,   216, ...,  2590,   160,    11]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_stylo[::].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIobPJiiRoXj"
      },
      "outputs": [],
      "source": [
        "y=df['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9PG1vSCRoXk"
      },
      "source": [
        "## Splitting for Stylometry based features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B0VFEDsRoXl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_stylo[::].values, y, train_size=0.8,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NbqAAo9RoXl"
      },
      "source": [
        "## RFC for Stylometry based features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-ZyjOxSRoXl",
        "outputId": "6cc44525-c7b6-4f8b-cdfb-f25e9caed80b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 67.05882352941175\n"
          ]
        }
      ],
      "source": [
        "rfclass = RFCL(max_depth=2,criterion='gini',max_features='log2',n_estimators=500)\n",
        "rfclass.fit(X_train, y_train)\n",
        "prediction_rfc = rfclass.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, prediction_rfc)\n",
        "print(\"accuracy:\",score*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK9M1SJCRoXm"
      },
      "source": [
        "## Content Based Methods (TFIDF,CountVectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTNL8ClTRoXn"
      },
      "outputs": [],
      "source": [
        "tfidf_vect = TfidfVectorizer(max_features=3000, analyzer='char',ngram_range=(2,3),stop_words='english') #CountVectorizer\n",
        "matrix = tfidf_vect.fit_transform(data)\n",
        "matrix=matrix.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqMaZMluRoXp",
        "outputId": "324070b5-6ec4-40b5-dccb-f8001b9a9352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.08018937, 0.00497391, 0.00372127, ..., 0.01363599, 0.        ,\n",
              "        0.00105585],\n",
              "       [0.07935589, 0.00233412, 0.00120057, ..., 0.00146644, 0.0004769 ,\n",
              "        0.00136258],\n",
              "       [0.08195314, 0.00368827, 0.00758837, ..., 0.00210654, 0.00205519,\n",
              "        0.00065245],\n",
              "       ...,\n",
              "       [0.10167476, 0.00243191, 0.00218903, ..., 0.00038197, 0.00223594,\n",
              "        0.00035492],\n",
              "       [0.08316931, 0.00290415, 0.00311203, ..., 0.00152047, 0.00089004,\n",
              "        0.00183662],\n",
              "       [0.06281336, 0.        , 0.        , ..., 0.        , 0.00335204,\n",
              "        0.00319246]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HR8REdfRoXr"
      },
      "source": [
        "## Splitting for Content based features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgAS1RyKRoXr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(matrix, y, train_size=0.8,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8f0Ln77RoXr"
      },
      "source": [
        "## RFC for content based methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRY5xvsbRoXs",
        "outputId": "8cf14653-c3bc-4229-b195-d9b0271e069e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 70.58823529411765\n"
          ]
        }
      ],
      "source": [
        "rfclass_content = RFCL(max_depth=2,criterion='gini',max_features='sqrt',\n",
        "                       n_estimators=500,class_weight='balanced').fit(X_train, y_train)\n",
        "prediction_rfc_content = rfclass_content.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, prediction_rfc_content)\n",
        "print(\"accuracy:\",score*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwo2bHNcRoXs"
      },
      "source": [
        "## Gradient Boosting Classifier Content Based "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wkhNDwVRoXt",
        "outputId": "553382b5-18fd-4bc2-9ed4-7b0515ecfff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "81.17647058823529"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_gbc = GRAD_BOOST(n_estimators=1000, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "clf_gbc.score(X_test, y_test)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4NxJcCBRoXt"
      },
      "source": [
        "## Logistic Reggression Content Based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBrmdPj3RoXt",
        "outputId": "d14104f1-ebf0-4a52-e7f1-5d523567818d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55.294117647058826"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LR=Log_Reg(class_weight='dict',solver='sag',max_iter=500).fit(X_train,y_train)\n",
        "LR.score(X_test,y_test)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE9dXVHmRoXu"
      },
      "source": [
        "## Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7925DTCRoXu"
      },
      "outputs": [],
      "source": [
        "clf_gbc_app = GRAD_BOOST(n_estimators=1000, learning_rate=1.0,max_depth=1, random_state=0).fit(matrix, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNpIlh65RoXu"
      },
      "source": [
        "## Saving the model into disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0B3prETRoXu",
        "outputId": "7e239daf-8e69-4345-a84c-f6a2c994a2fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['gbc_clf.sav']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_model = 'clf_gbc_model.sav'\n",
        "joblib.dump(clf_gbc_app, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hab7FaJTRoXv"
      },
      "source": [
        "## Input new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY1r4z6RRoXv",
        "outputId": "bb28dd8c-f829-48bf-9be7-e1fdf2c2349c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello 44jkn eo84 ng45o5 \n"
          ]
        }
      ],
      "source": [
        "test_data=input()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xUt9Db8RoXw"
      },
      "source": [
        "## Cleaning, Vectorization, Loading the model and Prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbHBYeaSRoXw",
        "outputId": "c2f64b75-5ea3-49d1-ac1f-9108cbf1c280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['female']\n"
          ]
        }
      ],
      "source": [
        "tdata={'con':[test_data]}\n",
        "df_test=pd.DataFrame(tdata)\n",
        "\n",
        "test_data = [] \n",
        "for lp in range(0, len(df_test)):\n",
        "    clean_data = re.sub('[^a-zA-Z]', ' ', str((df_test['con'][lp])))\n",
        "    clean_data.lower()\n",
        "    clean_data = clean_data.split()\n",
        "\n",
        "    clean_data=[word for word in clean_data if not word in stop_words]\n",
        "    clean_data = ' '.join(clean_data)\n",
        "    test_data.append(clean_data)\n",
        "\n",
        "mat_test = tfidf_vect.transform(test_data)\n",
        "\n",
        "loaded_model = joblib.load(file_model)\n",
        "result = loaded_model.predict(mat_test[[0]])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iSrp7_CRoXx"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "clean_data_test=[]\n",
        "for tok in range(0,len(df_test)):\n",
        "\n",
        "    tweet2 = re.sub(r'^RT[\\s]+', '', str(df_test['con'][tok]))\n",
        "    tweet2=tweet2.lower()\n",
        "    # remove digits\n",
        "    tweet2 = ''.join([i for i in tweet2 if not i.isdigit()])\n",
        "    # remove punctuation\n",
        "    tweet2=re.sub(r'[^\\w]', ' ', tweet2)\n",
        "    # remove words whose length is 3\n",
        "    tweet2= re.sub(r'\\b\\w{1,2}\\b', '', tweet2)\n",
        "    tweet2=tweet2.split()\n",
        "    # Removing stop words\n",
        "    tweet2 = [word for word in tweet2 if not word in stop_words]\n",
        "    tweet2 = ' '.join(tweet2)\n",
        "    clean_data_test.append(tweet2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpibtmVxRoXy",
        "outputId": "6c409e2f-b94a-42c9-80d9-f45deab15e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['female']\n"
          ]
        }
      ],
      "source": [
        "mat_test12 = tfidf_vect.transform(test_data)\n",
        "\n",
        "loaded_model = joblib.load(file_model)\n",
        "result = loaded_model.predict(mat_test12[[0]])\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}